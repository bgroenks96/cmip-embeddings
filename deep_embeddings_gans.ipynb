{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 CPUs\n",
      "numpy version: 1.15.4\n",
      "xarray version: 0.11.3\n",
      "matplotlib version: 3.0.2\n",
      "sklearn version: 0.20.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import itertools as it\n",
    "import os.path\n",
    "import multiprocessing as mp\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.rcsetup as rcsetup\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import mean_squared_error\n",
    "from keras import backend as K\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "from dcgan import DCGAN\n",
    "\n",
    "CPU_COUNT = mp.cpu_count()\n",
    "print('{} CPUs'.format(CPU_COUNT))\n",
    "print('numpy version: {}'.format(np.__version__))\n",
    "print('xarray version: {}'.format(xr.__version__))\n",
    "print('matplotlib version: {}'.format(matplotlib.__version__))\n",
    "print('sklearn version: {}'.format(sklearn.__version__))\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cached data file ./data/X_rcp26_all.npy\n",
      "loading land/sea mask data file\n",
      "loading cached data file ./data/X_rcp26_train.npy\n",
      "loading cached data file ./data/X_rcp26_valid.npy\n",
      "Loaded training data with shape: (11520, 72, 144, 2)\n",
      "Loaded validation data with shape: (5760, 72, 144, 2)\n"
     ]
    }
   ],
   "source": [
    "use_data_caching = True\n",
    "keep_original_data_loaded = False\n",
    "experiment = 'rcp26'\n",
    "\n",
    "model_names = xr.open_dataset('./data/{0}/{0}_m6_tas_pr.nc'.format(experiment)).coords['model']\n",
    "\n",
    "X_all_filename = './data/X_{}_all.npy'.format(experiment)\n",
    "X_train_filename = './data/X_{}_train.npy'.format(experiment)\n",
    "X_valid_filename = './data/X_{}_valid.npy'.format(experiment)\n",
    "ls_mask_filename = './data/lsmask_cmip3_144.nc'\n",
    "if use_data_caching and os.path.isfile(X_all_filename):\n",
    "    print('loading cached data file {}'.format(X_all_filename))\n",
    "    X_all = np.load(X_all_filename)\n",
    "else:\n",
    "    print('loading and processing dataset for experiment {}'.format(experiment))\n",
    "    X_ds = xr.open_dataset('./data/{0}/{0}_m6_tas_pr.nc'.format(experiment))\n",
    "    X_arr = X_ds.to_array().transpose('model', 'time', 'lat', 'lon', 'variable')\n",
    "    X_all = X_arr.values\n",
    "    nan_count = np.product(X_all.shape) - np.count_nonzero(~np.isnan(X_all))\n",
    "    print('found {} NaN values in data'.format(nan_count))\n",
    "    assert nan_count == 0\n",
    "    # standardize variables\n",
    "    for i in range(N_vars):\n",
    "        stddev = np.std(X_all[:,:,:,:,i])\n",
    "        X_all[:,:,:,:,i] = X_all[:,:,:,:,i] / stddev\n",
    "    if use_data_caching:\n",
    "        np.save(X_all_filename, X_all)\n",
    "        \n",
    "if os.path.isfile(ls_mask_filename):\n",
    "    print('loading land/sea mask data file')\n",
    "    X_ls_mask = xr.open_dataset(ls_mask_filename)\n",
    "    X_sea_mask = 1 - X_ls_mask.to_array().values.reshape((1, N_lat, N_lon, 1))\n",
    "    \n",
    "N_models, N_time, N_lat, N_lon, N_vars = X_all.shape\n",
    "BATCH_SIZE = N_models*N_time // 20\n",
    "    \n",
    "N_models_train = N_models - 2\n",
    "N_models_valid = N_models - N_models_train\n",
    "\n",
    "if use_data_caching and os.path.isfile(X_train_filename):\n",
    "    print('loading cached data file {}'.format(X_train_filename))\n",
    "    X_train = np.load(X_train_filename)\n",
    "else:\n",
    "    print('generating training data')\n",
    "    X_train = np.hstack(X_all[:N_models_train]).reshape((N_models_train*N_time, N_lat, N_lon, N_vars))\n",
    "    if use_data_caching:\n",
    "        np.save(X_train_filename, X_train)\n",
    "\n",
    "if use_data_caching and os.path.isfile(X_valid_filename):\n",
    "    print('loading cached data file {}'.format(X_valid_filename))\n",
    "    X_valid = np.load(X_valid_filename)\n",
    "else:\n",
    "    print('generating validation data')\n",
    "    X_valid = np.hstack(X_all[N_models_train:]).reshape((N_models_valid*N_time, N_lat, N_lon, N_vars))\n",
    "    if use_data_caching:\n",
    "        np.save(X_valid_filename, X_valid)\n",
    "\n",
    "if not keep_original_data_loaded:\n",
    "    del X_all\n",
    "print('Loaded training data with shape: {}'.format(X_train.shape))\n",
    "print('Loaded validation data with shape: {}'.format(X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "def plot_image_map(X, cmap=\"seismic\", title=\"\", min_max=None):\n",
    "    basemap = Basemap(lat_0=0, lon_0=180)\n",
    "    img = basemap.imshow(X, origin='lower', cmap=cmap)\n",
    "    basemap.drawcoastlines()\n",
    "    if min_max is not None:\n",
    "        img.set_clim(vmin=min_max[0], vmax=min_max[1])\n",
    "    plt.colorbar(fraction=0.035, pad=0.04)\n",
    "    plt.title(title)\n",
    "\n",
    "def plot_var_spatial(X, model, name=\"model\", cmap='brg', t=0, c=0):\n",
    "    X_t = np.expand_dims(X[t], axis=0)\n",
    "    X_pred = model.predict(X_t)\n",
    "    fig = plt.figure(figsize=(16,14))\n",
    "    avg_x = np.mean(X_t)\n",
    "    std_x = np.std(X_t)\n",
    "    min_x = avg_x - 2*std_x\n",
    "    max_x = avg_x + 2*std_x\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_image_map(X_t[0,:,:,c], cmap=cmap, title='{}, t={}'.format(name, t))\n",
    "    plt.clim(vmin=min_x, vmax=max_x)\n",
    "    plt.subplot(1,2,2)\n",
    "    plot_image_map(X_pred[0,:,:,c], cmap=cmap, title='{}, t={}, reconstructed'.format(name, t))\n",
    "    plt.clim(vmin=min_x, vmax=max_x)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_err_spatial(X, model, target_shape=(1, N_lat, N_lon, N_vars), cmap=\"Reds\", name=\"\", t=0,c=0):\n",
    "    plt.figure(figsize=(7,6))\n",
    "    X_t = np.expand_dims(X[t], axis=0)\n",
    "    X_pred = model.predict(X_t)\n",
    "    X_err = np.abs(X_t - X_pred)[0,:,:,c]\n",
    "    plot_image_map(X_err.reshape((N_lat, N_lon)), cmap=cmap, title='{}, total absolute error, t={}'.format(name, t))\n",
    "    \n",
    "def plot_var_time(X, model, model_name=\"model\", name=\"\", c=0):\n",
    "    X_orig = X\n",
    "    X_pred = np.zeros((0, *X_orig.shape[1:]))\n",
    "    batch_size = X_orig.shape[0] // 10\n",
    "    for i in range(10):\n",
    "        X_next = model.predict_on_batch(X_orig[i*batch_size:(i+1)*batch_size])\n",
    "        X_pred = np.concatenate([X_pred, X_next], axis=0)\n",
    "    plt.plot(range(X_orig.shape[0]), np.mean(X_orig, axis=(1,2))[:,c], c='blue')\n",
    "    plt.title('{}, global average, original'.format(name))\n",
    "    plt.plot(range(X_orig.shape[0]), np.mean(X_pred, axis=(1,2))[:,c], ':', c='red')\n",
    "    plt.title('{}, global average, reconstructed'.format(name))\n",
    "    plt.legend(['original', model_name])\n",
    "    \n",
    "def show_activations(X, model, layer, output_shape, t=0, name=\"\"):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "    layer_fn = K.function(inputs, [layer.output])\n",
    "    layer_out = layer_fn([0, X])[0]\n",
    "    z_0 = layer_out[t].reshape(output_shape)\n",
    "    plt.imshow(z_0, origin='lower')\n",
    "    plt.title(name)\n",
    "    plt.colorbar()\n",
    "    \n",
    "def show_conv_activations(X, model, layer, output_shape, t=0, c=0, name=\"\"):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "    layer_fn = K.function(inputs, [layer.output])\n",
    "    layer_out = layer_fn([0, X])[0]\n",
    "    print(layer_out.shape)\n",
    "    if layer_out.shape[-1] == 32:\n",
    "        n_rows, n_cols = 4,8\n",
    "    elif layer_out.shape[-1] == 16:\n",
    "        n_rows, n_cols = 4,4\n",
    "    elif layer_out.shape[-1] == 8:\n",
    "        n_rows, n_cols = 2,4\n",
    "    else:\n",
    "        raise Exception('unsupported channel count')\n",
    "    z_0 = layer_out[t].reshape(output_shape)\n",
    "    plt.figure(figsize=(8*n_cols,6*n_rows))\n",
    "    for i in range(layer_out.shape[-1]):\n",
    "        plt.subplot(n_rows, n_cols, i+1)\n",
    "        plt.imshow(z_0[:,:,i], origin='lower')\n",
    "        plt.title('{}, c={}'.format(name, c))\n",
    "        plt.colorbar(fraction=0.030, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 36, 72, 32)        608       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 36, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 36, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 18, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 19, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 19, 37, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 19, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 19, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 10, 19, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 10, 19, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 10, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 19, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 10, 19, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 10, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 10, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12160)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 12161     \n",
      "=================================================================\n",
      "Total params: 78,081\n",
      "Trainable params: 77,761\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 20736)             2674944   \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 18, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 36, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 36, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 36, 72, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 36, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 72, 144, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 72, 144, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 72, 144, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 72, 144, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 72, 144, 2)        578       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 72, 144, 2)        0         \n",
      "=================================================================\n",
      "Total params: 2,694,274\n",
      "Trainable params: 2,694,146\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/brian/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 1.123395, acc.: 38.89%] [G loss: 0.580213]\n",
      "1 [D loss: 0.926342, acc.: 47.92%] [G loss: 0.678049]\n",
      "2 [D loss: 0.908646, acc.: 43.75%] [G loss: 0.766170]\n",
      "3 [D loss: 1.044259, acc.: 34.38%] [G loss: 0.897717]\n",
      "4 [D loss: 0.972787, acc.: 41.32%] [G loss: 0.896455]\n",
      "5 [D loss: 0.990627, acc.: 40.28%] [G loss: 0.848737]\n",
      "6 [D loss: 0.999449, acc.: 37.85%] [G loss: 0.813974]\n",
      "7 [D loss: 1.028977, acc.: 35.07%] [G loss: 0.795550]\n",
      "8 [D loss: 1.084630, acc.: 31.60%] [G loss: 0.913919]\n",
      "9 [D loss: 1.187717, acc.: 31.25%] [G loss: 0.768235]\n",
      "10 [D loss: 1.120252, acc.: 32.99%] [G loss: 0.825300]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e353c7d03f79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDCGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m144\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/cu-csci/projects/cmip-embeddings/dcgan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, epochs, batch_size, save_interval)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Train the discriminator (real classified as ones and generated as zeros)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0md_loss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0md_loss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m             \u001b[0md_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_loss_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan = DCGAN(img_shape=X_train.shape[1:], latent_dims=128)\n",
    "gan.train(X_train, epochs=100, batch_size=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
