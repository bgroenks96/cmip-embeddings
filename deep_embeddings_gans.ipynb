{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 CPUs\n",
      "numpy version: 1.15.4\n",
      "xarray version: 0.11.3\n",
      "matplotlib version: 3.0.2\n",
      "sklearn version: 0.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import itertools as it\n",
    "import os.path\n",
    "import multiprocessing as mp\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.rcsetup as rcsetup\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from keras.layers import *\n",
    "from keras.regularizers import l1,l2\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import mean_squared_error\n",
    "from keras import backend as K\n",
    "from livelossplot.keras import PlotLossesCallback\n",
    "from dcgan import DCGAN\n",
    "\n",
    "CPU_COUNT = mp.cpu_count()\n",
    "print('{} CPUs'.format(CPU_COUNT))\n",
    "print('numpy version: {}'.format(np.__version__))\n",
    "print('xarray version: {}'.format(xr.__version__))\n",
    "print('matplotlib version: {}'.format(matplotlib.__version__))\n",
    "print('sklearn version: {}'.format(sklearn.__version__))\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading cached data file ./data/X_rcp26_all.npy\n",
      "loading land/sea mask data file\n",
      "loading cached data file ./data/X_rcp26_train.npy\n",
      "loading cached data file ./data/X_rcp26_valid.npy\n",
      "Loaded training data with shape: (11520, 72, 144, 2)\n",
      "Loaded validation data with shape: (5760, 72, 144, 2)\n"
     ]
    }
   ],
   "source": [
    "use_data_caching = True\n",
    "keep_original_data_loaded = False\n",
    "experiment = 'rcp26'\n",
    "\n",
    "model_names = xr.open_dataset('./data/{0}/{0}_m6_tas_pr.nc'.format(experiment)).coords['model']\n",
    "\n",
    "X_all_filename = './data/X_{}_all.npy'.format(experiment)\n",
    "X_train_filename = './data/X_{}_train.npy'.format(experiment)\n",
    "X_valid_filename = './data/X_{}_valid.npy'.format(experiment)\n",
    "ls_mask_filename = './data/lsmask_cmip3_144.nc'\n",
    "if use_data_caching and os.path.isfile(X_all_filename):\n",
    "    print('loading cached data file {}'.format(X_all_filename))\n",
    "    X_all = np.load(X_all_filename)\n",
    "else:\n",
    "    print('loading and processing dataset for experiment {}'.format(experiment))\n",
    "    X_ds = xr.open_dataset('./data/{0}/{0}_m6_tas_pr.nc'.format(experiment))\n",
    "    X_arr = X_ds.to_array().transpose('model', 'time', 'lat', 'lon', 'variable')\n",
    "    X_all = X_arr.values\n",
    "    nan_count = np.product(X_all.shape) - np.count_nonzero(~np.isnan(X_all))\n",
    "    print('found {} NaN values in data'.format(nan_count))\n",
    "    assert nan_count == 0\n",
    "    # standardize variables\n",
    "    for i in range(X_all.shape[-1]):\n",
    "        stddev = np.std(X_all[:,:,:,:,i])\n",
    "        X_all[:,:,:,:,i] = X_all[:,:,:,:,i] / stddev\n",
    "    if use_data_caching:\n",
    "        np.save(X_all_filename, X_all)\n",
    "    \n",
    "N_models, N_time, N_lat, N_lon, N_vars = X_all.shape\n",
    "BATCH_SIZE = N_models*N_time // 20\n",
    "    \n",
    "N_models_train = N_models - 2\n",
    "N_models_valid = N_models - N_models_train\n",
    "N_train = N_models_train*N_time\n",
    "N_valid = N_models_valid*N_time\n",
    "\n",
    "if os.path.isfile(ls_mask_filename):\n",
    "    print('loading land/sea mask data file')\n",
    "    X_ls_mask = xr.open_dataset(ls_mask_filename)\n",
    "    X_sea_mask = 1 - X_ls_mask.to_array().values.reshape((1, N_lat, N_lon, 1))\n",
    "\n",
    "if use_data_caching and os.path.isfile(X_train_filename):\n",
    "    print('loading cached data file {}'.format(X_train_filename))\n",
    "    X_train = np.load(X_train_filename)\n",
    "else:\n",
    "    print('generating training data')\n",
    "    X_train = np.hstack(X_all[:N_models_train]).reshape((N_models_train*N_time, N_lat, N_lon, N_vars))\n",
    "    if use_data_caching:\n",
    "        np.save(X_train_filename, X_train)\n",
    "\n",
    "if use_data_caching and os.path.isfile(X_valid_filename):\n",
    "    print('loading cached data file {}'.format(X_valid_filename))\n",
    "    X_valid = np.load(X_valid_filename)\n",
    "else:\n",
    "    print('generating validation data')\n",
    "    X_valid = np.hstack(X_all[N_models_train:]).reshape((N_models_valid*N_time, N_lat, N_lon, N_vars))\n",
    "    if use_data_caching:\n",
    "        np.save(X_valid_filename, X_valid)\n",
    "\n",
    "if not keep_original_data_loaded:\n",
    "    del X_all\n",
    "    \n",
    "X_train_sea = X_train * X_sea_mask\n",
    "X_valid_sea = X_valid * X_sea_mask\n",
    "\n",
    "print('Loaded training data with shape: {}'.format(X_train.shape))\n",
    "print('Loaded validation data with shape: {}'.format(X_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "def plot_image_map(X, cmap=\"seismic\", title=\"\", min_max=None):\n",
    "    basemap = Basemap(lat_0=0, lon_0=180)\n",
    "    img = basemap.imshow(X, origin='lower', cmap=cmap)\n",
    "    basemap.drawcoastlines()\n",
    "    if min_max is not None:\n",
    "        img.set_clim(vmin=min_max[0], vmax=min_max[1])\n",
    "    plt.colorbar(fraction=0.035, pad=0.04)\n",
    "    plt.title(title)\n",
    "\n",
    "def plot_var_spatial(X, model, name=\"model\", cmap='brg', t=0, c=0):\n",
    "    X_t = np.expand_dims(X[t], axis=0)\n",
    "    X_pred = model.predict(X_t)\n",
    "    fig = plt.figure(figsize=(16,14))\n",
    "    avg_x = np.mean(X_t)\n",
    "    std_x = np.std(X_t)\n",
    "    min_x = avg_x - 2*std_x\n",
    "    max_x = avg_x + 2*std_x\n",
    "    plt.subplot(1,2,1)\n",
    "    plot_image_map(X_t[0,:,:,c], cmap=cmap, title='{}, t={}'.format(name, t))\n",
    "    plt.clim(vmin=min_x, vmax=max_x)\n",
    "    plt.subplot(1,2,2)\n",
    "    plot_image_map(X_pred[0,:,:,c], cmap=cmap, title='{}, t={}, reconstructed'.format(name, t))\n",
    "    plt.clim(vmin=min_x, vmax=max_x)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_err_spatial(X, model, target_shape=(1, N_lat, N_lon, N_vars), cmap=\"Reds\", name=\"\", t=0,c=0):\n",
    "    plt.figure(figsize=(7,6))\n",
    "    X_t = np.expand_dims(X[t], axis=0)\n",
    "    X_pred = model.predict(X_t)\n",
    "    X_err = np.abs(X_t - X_pred)[0,:,:,c]\n",
    "    plot_image_map(X_err.reshape((N_lat, N_lon)), cmap=cmap, title='{}, total absolute error, t={}'.format(name, t))\n",
    "    \n",
    "def plot_var_time(X, model, model_name=\"model\", name=\"\", c=0):\n",
    "    X_orig = X\n",
    "    X_pred = np.zeros((0, *X_orig.shape[1:]))\n",
    "    batch_size = X_orig.shape[0] // 10\n",
    "    for i in range(10):\n",
    "        X_next = model.predict_on_batch(X_orig[i*batch_size:(i+1)*batch_size])\n",
    "        X_pred = np.concatenate([X_pred, X_next], axis=0)\n",
    "    plt.plot(range(X_orig.shape[0]), np.mean(X_orig, axis=(1,2))[:,c], c='blue')\n",
    "    plt.title('{}, global average, original'.format(name))\n",
    "    plt.plot(range(X_orig.shape[0]), np.mean(X_pred, axis=(1,2))[:,c], ':', c='red')\n",
    "    plt.title('{}, global average, reconstructed'.format(name))\n",
    "    plt.legend(['original', model_name])\n",
    "    \n",
    "def show_activations(X, model, layer, output_shape, t=0, name=\"\"):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "    layer_fn = K.function(inputs, [layer.output])\n",
    "    layer_out = layer_fn([0, X])[0]\n",
    "    z_0 = layer_out[t].reshape(output_shape)\n",
    "    plt.imshow(z_0, origin='lower')\n",
    "    plt.title(name)\n",
    "    plt.colorbar()\n",
    "    \n",
    "def show_conv_activations(X, model, layer, output_shape, t=0, c=0, name=\"\"):\n",
    "    inputs = [K.learning_phase()] + model.inputs\n",
    "    layer_fn = K.function(inputs, [layer.output])\n",
    "    layer_out = layer_fn([0, X])[0]\n",
    "    print(layer_out.shape)\n",
    "    if layer_out.shape[-1] == 32:\n",
    "        n_rows, n_cols = 4,8\n",
    "    elif layer_out.shape[-1] == 16:\n",
    "        n_rows, n_cols = 4,4\n",
    "    elif layer_out.shape[-1] == 8:\n",
    "        n_rows, n_cols = 2,4\n",
    "    else:\n",
    "        raise Exception('unsupported channel count')\n",
    "    z_0 = layer_out[t].reshape(output_shape)\n",
    "    plt.figure(figsize=(8*n_cols,6*n_rows))\n",
    "    for i in range(layer_out.shape[-1]):\n",
    "        plt.subplot(n_rows, n_cols, i+1)\n",
    "        plt.imshow(z_0[:,:,i], origin='lower')\n",
    "        plt.title('{}, c={}'.format(name, c))\n",
    "        plt.colorbar(fraction=0.030, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/brian/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/brian/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 36, 72, 32)        608       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 36, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 36, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 18, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 19, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 19, 37, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 19, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 19, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 19, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 19, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 10, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 19, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 19, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 10, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12160)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 12161     \n",
      "=================================================================\n",
      "Total params: 78,081\n",
      "Trainable params: 77,761\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 20736)             2674944   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 18, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 36, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 36, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 36, 72, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 36, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 72, 144, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 72, 144, 32)       9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 72, 144, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 72, 144, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 72, 144, 2)        578       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 72, 144, 2)        0         \n",
      "=================================================================\n",
      "Total params: 2,694,274\n",
      "Trainable params: 2,694,146\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = DCGAN(img_shape=X_train.shape[1:], latent_dims=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/brian/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/brian/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 1.104907, acc.: 38.19%] [G loss: 0.513509]\n",
      "1 [D loss: 0.976704, acc.: 46.88%] [G loss: 0.678277]\n",
      "2 [D loss: 0.836587, acc.: 52.78%] [G loss: 0.779451]\n",
      "3 [D loss: 0.883030, acc.: 48.96%] [G loss: 0.903299]\n",
      "4 [D loss: 0.946261, acc.: 42.36%] [G loss: 0.919827]\n",
      "5 [D loss: 0.969149, acc.: 43.06%] [G loss: 0.849023]\n",
      "6 [D loss: 1.004154, acc.: 42.01%] [G loss: 0.771782]\n",
      "7 [D loss: 0.991606, acc.: 37.50%] [G loss: 0.906908]\n",
      "8 [D loss: 1.066399, acc.: 36.46%] [G loss: 0.976532]\n",
      "9 [D loss: 1.023476, acc.: 34.03%] [G loss: 0.817208]\n",
      "10 [D loss: 0.971809, acc.: 42.36%] [G loss: 0.846376]\n",
      "11 [D loss: 0.950653, acc.: 42.01%] [G loss: 0.798149]\n",
      "12 [D loss: 1.040205, acc.: 34.72%] [G loss: 0.869416]\n",
      "13 [D loss: 0.994012, acc.: 40.97%] [G loss: 0.876984]\n",
      "14 [D loss: 0.901178, acc.: 47.92%] [G loss: 1.008154]\n",
      "15 [D loss: 0.932318, acc.: 45.83%] [G loss: 0.967163]\n",
      "16 [D loss: 0.864751, acc.: 51.04%] [G loss: 1.146248]\n",
      "17 [D loss: 0.832770, acc.: 50.35%] [G loss: 1.006929]\n",
      "18 [D loss: 0.863254, acc.: 50.35%] [G loss: 1.112260]\n",
      "19 [D loss: 0.787436, acc.: 53.47%] [G loss: 1.094285]\n",
      "20 [D loss: 0.799064, acc.: 57.99%] [G loss: 1.130600]\n",
      "21 [D loss: 0.909165, acc.: 47.92%] [G loss: 1.108833]\n",
      "22 [D loss: 0.794899, acc.: 55.56%] [G loss: 1.179936]\n",
      "23 [D loss: 0.743227, acc.: 56.94%] [G loss: 1.331572]\n",
      "24 [D loss: 0.846155, acc.: 51.39%] [G loss: 1.254080]\n",
      "25 [D loss: 0.819113, acc.: 54.51%] [G loss: 1.253047]\n",
      "26 [D loss: 0.731848, acc.: 58.33%] [G loss: 1.371660]\n",
      "27 [D loss: 0.801253, acc.: 55.56%] [G loss: 1.322735]\n",
      "28 [D loss: 0.952715, acc.: 46.88%] [G loss: 1.180736]\n",
      "29 [D loss: 0.899906, acc.: 52.08%] [G loss: 1.311678]\n",
      "30 [D loss: 1.021719, acc.: 44.79%] [G loss: 1.373397]\n",
      "31 [D loss: 0.855416, acc.: 50.69%] [G loss: 1.411612]\n",
      "32 [D loss: 0.899387, acc.: 47.92%] [G loss: 1.284363]\n",
      "33 [D loss: 1.044035, acc.: 41.67%] [G loss: 1.353654]\n",
      "34 [D loss: 0.997769, acc.: 46.18%] [G loss: 1.405798]\n",
      "35 [D loss: 0.904971, acc.: 50.35%] [G loss: 1.469406]\n",
      "36 [D loss: 0.984191, acc.: 47.57%] [G loss: 1.398308]\n",
      "37 [D loss: 1.037935, acc.: 43.40%] [G loss: 1.271537]\n",
      "38 [D loss: 0.956377, acc.: 47.92%] [G loss: 1.415033]\n",
      "39 [D loss: 0.933147, acc.: 46.53%] [G loss: 1.354375]\n",
      "40 [D loss: 1.137164, acc.: 35.76%] [G loss: 1.201016]\n",
      "41 [D loss: 1.243699, acc.: 32.29%] [G loss: 1.149707]\n",
      "42 [D loss: 1.190593, acc.: 33.33%] [G loss: 1.229357]\n",
      "43 [D loss: 1.237019, acc.: 30.21%] [G loss: 1.227782]\n",
      "44 [D loss: 1.154076, acc.: 30.56%] [G loss: 1.141657]\n",
      "45 [D loss: 1.241368, acc.: 29.51%] [G loss: 1.198968]\n",
      "46 [D loss: 1.236682, acc.: 26.04%] [G loss: 1.095111]\n",
      "47 [D loss: 1.224553, acc.: 24.65%] [G loss: 1.174736]\n",
      "48 [D loss: 1.086339, acc.: 35.42%] [G loss: 1.342895]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f81967ba2e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m144\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/workspace/cu-csci/projects/cmip-embeddings/dcgan.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, epochs, batch_size, save_interval)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;31m# Train the generator (wants discriminator to mistake images as real)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;31m# Plot the progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.train(X_train, epochs=100, batch_size=144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
