{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/curc/tools/jupyter/software/prod/jupyterhub/lib/python3.5/site-packages', '/curc/tools/jupyter/software/prod/jupyterhub/lib64/python3.5/site-packages', '/curc/tools/jupyter/software/prod/jupyterhub/sitecustomize', '/curc/sw/python/3.5.1/lib/python35.zip', '/curc/sw/python/3.5.1/lib/python3.5', '/curc/sw/python/3.5.1/lib/python3.5/plat-linux', '/curc/sw/python/3.5.1/lib/python3.5/lib-dynload', '/curc/sw/python/3.5.1/lib/python3.5/site-packages', '/curc/tools/jupyter/software/prod/jupyterhub/lib/python3.5/site-packages/IPython/extensions', '/home/brgr6137/.ipython', '/projects/brgr6137/pyenv35/lib/python3.5/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import os\n",
    "import io\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data download helper scripts\n",
    "\n",
    "Helper code for automating download of raw data directly from KNMI. Data must have been recently generated and published on KNMI server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wget'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7dfecc91f071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mwget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mN_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m65\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtasmin_uri_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://climexp.knmi.nl/data/icmip5_tasmin_Amon_ens_rcp26_-125--65E_25-50N_n_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtasmax_uri_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://climexp.knmi.nl/data/icmip5_tasmax_Amon_ens_rcp26_-125--65E_25-50N_n_'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wget'"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "N_models = 65\n",
    "tasmin_uri_base = 'https://climexp.knmi.nl/data/icmip5_tasmin_Amon_ens_rcp26_-125--65E_25-50N_n_'\n",
    "tasmax_uri_base = 'https://climexp.knmi.nl/data/icmip5_tasmax_Amon_ens_rcp26_-125--65E_25-50N_n_'\n",
    "pr_uri_base = 'https://climexp.knmi.nl/data/icmip5_pr_Amon_ens_rcp26_-125--65E_25-50N_n_'\n",
    "evspspl_uri_base = 'https://climexp.knmi.nl/data/icmip5_evspsbl_Amon_ens_rcp26_-125--65E_25-50N_n_'\n",
    "pme_uri_base = 'https://climexp.knmi.nl/data/icmip5_pme_Amon_ens_rcp26_-125--65E_25-50N_n_'\n",
    "hurs_uri_base = 'https://climexp.knmi.nl/data/icmip5_hurs_Amon_ens_rcp26_-125--65E_25-50N_n_'\n",
    "psl_uri_base = 'https://climexp.knmi.nl/data/icmip5_psl_Amon_ens_rcp26_-125--65E_25-50N_n_'\n",
    "for i in range(63, N_models):\n",
    "    uri = '{}{:03d}.dat'.format(psl_uri_base, i)\n",
    "    print('Downloading model {}/{} from {}'.format(i+1, N_models, uri))\n",
    "    wget.download(uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for raw data files\n",
    "\n",
    "1. Parse and save raw data into per variable datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data_dir = 'raw_data'\n",
    "var_names = ['tas','tasmin','tasmax','pr','pme','evspsbl']\n",
    "months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "# create data/ directory\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "def parse_model_file(filename: str) -> pd.DataFrame:\n",
    "    def parse_header(lines: List[str]) -> Tuple[Dict[str, str], int]:\n",
    "        metadata = dict()\n",
    "        for (i, line) in enumerate(lines):\n",
    "            # stop at end of header\n",
    "            if not line.startswith('#'):\n",
    "                return metadata, i\n",
    "            # skip header lines that not in key-value format\n",
    "            if not '::' in line:\n",
    "                continue\n",
    "            kv = line.replace('#', '').split('::')\n",
    "            assert len(kv) == 2\n",
    "            metadata[kv[0].strip()] = kv[1].strip()\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        metadata, i = parse_header(lines)\n",
    "        csv_str = \"\".join(lines[i:])\n",
    "        df = pd.read_csv(io.StringIO(csv_str), delim_whitespace=True, header=None)\n",
    "        years = df[0]\n",
    "        df = df.drop(columns=[0])\n",
    "        name = '{}_{}'.format(metadata['model_id'], metadata['realization'])\n",
    "        xdarr = xr.DataArray(df, coords=[years, months], dims=['years', 'months'], attrs=metadata, name=name)\n",
    "        return xdarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for var in var_names:\n",
    "    dirname = './{}/{}'.format(raw_data_dir, var)\n",
    "    models = dict()\n",
    "    for file in filter(lambda f: not f.startswith('.'), os.listdir(dirname)):\n",
    "        xdarr = parse_model_file('{}/{}'.format(dirname, file))\n",
    "        models[xdarr.name] = xdarr\n",
    "    ds = xr.Dataset(models)\n",
    "    ds.to_netcdf(\"./data/{}.nc\".format(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Collect and organize raw data to construct per-model datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def center_monthly_means(xdarr: xr.DataArray) -> xr.DataArray:\n",
    "    attrs = xdarr.attrs\n",
    "    means = xdarr.mean(dim='years', keep_attrs=True)\n",
    "    xdarr = xdarr - means\n",
    "    xdarr.attrs = attrs\n",
    "    return xdarr\n",
    "\n",
    "def flatten_months(xdarr: xr.DataArray) -> xr.DataArray:\n",
    "    d0,d1 = xdarr.shape\n",
    "    xdarr = xdarr.stack(time=('years','months'))\n",
    "    assert(len(xdarr.shape) == 1)\n",
    "    assert(xdarr.shape[0] == d0*d1)\n",
    "    return xdarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing model data for tas\n",
      "building data array for tas\n",
      "processing model data for tasmin\n",
      "building data array for tasmin\n",
      "processing model data for tasmax\n",
      "building data array for tasmax\n",
      "processing model data for pr\n",
      "building data array for pr\n",
      "processing model data for pme\n",
      "building data array for pme\n",
      "processing model data for evspsbl\n",
      "building data array for evspsbl\n",
      "building dataset for all variables\n",
      "<xarray.Dataset>\n",
      "Dimensions:  (models: 40, time: 2880)\n",
      "Coordinates:\n",
      "  * models   (models) <U16 'CCSM4_1' 'CCSM4_2' ... 'MRI-CGCM3_1' 'NorESM1-M_1'\n",
      "  * time     (time) MultiIndex\n",
      "  - years    (time) int64 1861 1861 1861 1861 1861 ... 1863 1863 1863 1863 1863\n",
      "  - months   (time) object 'Jan' 'Feb' 'Mar' 'Apr' ... 'Mar' 'Apr' 'May' 'Jun'\n",
      "Data variables:\n",
      "    tas      (models, time) float64 -1.232 -0.9981 -0.3392 ... 1.091 1.176\n",
      "    tasmin   (models, time) float64 -0.8222 -3.135 -0.5128 ... 1.486 0.5544\n",
      "    tasmax   (models, time) float64 -0.5729 -2.731 -0.5294 ... 1.633 -0.1004\n",
      "    pr       (models, time) float64 -5.454e-07 -3.203e-06 ... -1.802e-06\n",
      "    pme      (models, time) float64 -1.763e-07 -3.496e-06 ... -5.584e-06\n",
      "    evspsbl  (models, time) float64 -3.692e-07 2.936e-07 ... 3.288e-06 3.781e-06\n"
     ]
    }
   ],
   "source": [
    "var_datasets = dict()\n",
    "for var in var_names:\n",
    "    xds = xr.open_dataset('data/{}.nc'.format(var))\n",
    "    var_datasets[var] = xds\n",
    "    \n",
    "common_models = set()\n",
    "for var, ds in var_datasets.items():\n",
    "    if len(common_models) == 0:\n",
    "        common_models |= ds.data_vars.keys()\n",
    "    else:\n",
    "        common_models &= ds.data_vars.keys()\n",
    "var_data = dict()\n",
    "for var, ds in var_datasets.items():\n",
    "    xs = []\n",
    "    model_names = []\n",
    "    print('processing model data for {}'.format(var))\n",
    "    for model in sorted(filter(lambda m: m in common_models, ds.data_vars.keys())):\n",
    "        xdarr = ds.data_vars[model]\n",
    "        # fill NaNs\n",
    "        xdarr = xdarr.ffill(dim='years')\n",
    "        xdarr = xdarr.bfill(dim='years')\n",
    "        xdarr = center_monthly_means(xdarr)\n",
    "        xdarr = flatten_months(xdarr)\n",
    "        xs.append(xdarr)\n",
    "        model_names.append(model)\n",
    "    print('building data array for {}'.format(var))\n",
    "    var_dr = xr.DataArray(xs, [('models', model_names),('time', xs[0].indexes['time'])])\n",
    "    var_data[var] = var_dr\n",
    "\n",
    "print('building dataset for all variables')\n",
    "model_time_var_ds = xr.Dataset(var_data)\n",
    "print(model_time_var_ds)\n",
    "model_time_var_ds = model_time_var_ds.reset_index('time')\n",
    "print(model_time_var_ds)\n",
    "model_time_var_ds.to_netcdf('./data/{}.nc'.format('models_all_vars_vs_time'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import SpectralEmbedding, TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dtw import dtw, accelerated_dtw\n",
    "from typing import Callable\n",
    "from multiprocessing import Pool\n",
    "from itertools import product\n",
    "\n",
    "def _pardtw(params):\n",
    "    x_i, x_j, metric = params\n",
    "    d,cost,acc_cost,path = accelerated_dtw(x_i, x_j, metric)\n",
    "    return d\n",
    "\n",
    "def pdtw(X, metric: str, verbose: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns a function d: X x X -> R that calculates DTW distances from\n",
    "    a tensor space X, where the second dim of X is time.\n",
    "    X : data matrix\n",
    "    metric : metric name to use for DTW (see scipy cdist)\n",
    "    \"\"\"\n",
    "    n, t, m = X.shape\n",
    "    pool = Pool(4)\n",
    "    results = pool.map(_pardtw, [(X[i], X[j], metric) for i in range(n) for j in range(n)])\n",
    "    return np.array(results).reshape((n,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray (models: 40, time: 2880, variable: 6)>\n",
      "array([[[ -1.232390e+00,  -8.221712e-01, ...,  -1.762584e-07,  -3.691904e-07],\n",
      "        [ -9.980754e-01,  -3.134700e+00, ...,  -3.496395e-06,   2.935993e-07],\n",
      "        ..., \n",
      "        [  1.093070e+00,   9.386808e-01, ...,  -3.006784e-06,   2.310148e-06],\n",
      "        [  1.049638e+00,   1.553081e+00, ...,   5.685991e-06,   2.558547e-06]],\n",
      "\n",
      "       [[ -6.226550e-01,  -2.455808e-01, ...,   1.469825e-06,   5.744220e-07],\n",
      "        [ -8.767850e-01,   5.197417e-01, ...,  -7.336508e-06,  -3.874350e-08],\n",
      "        ..., \n",
      "        [  9.840863e-01,   1.147870e+00, ...,  -1.667757e-06,   2.476872e-07],\n",
      "        [  3.382746e-01,   7.926292e-01, ...,  -5.932489e-06,   3.007603e-06]],\n",
      "\n",
      "       ..., \n",
      "       [[ -1.374901e+00,  -1.929253e+00, ...,   1.195963e-05,  -6.273888e-06],\n",
      "        [ -5.095788e-01,  -3.281883e+00, ...,   7.633096e-06,   1.095362e-06],\n",
      "        ..., \n",
      "        [  4.450033e-01,   8.567608e-01, ...,  -1.969318e-06,   2.737182e-06],\n",
      "        [  5.749437e-01,   1.901202e+00, ...,  -3.146661e-06,  -2.184425e-06]],\n",
      "\n",
      "       [[ -4.495746e-01,  -1.013100e+00, ...,   6.291128e-06,  -3.593820e-06],\n",
      "        [ -4.946579e-01,  -1.308242e-01, ...,   1.386026e-06,   2.252870e-06],\n",
      "        ..., \n",
      "        [  1.090548e+00,   1.485770e+00, ...,  -3.829500e-06,   3.288378e-06],\n",
      "        [  1.176182e+00,   5.543529e-01, ...,  -5.583992e-06,   3.781489e-06]]])\n",
      "Coordinates:\n",
      "  * variable  (variable) <U7 'tas' 'tasmin' 'tasmax' 'pr' 'pme' 'evspsbl'\n",
      "    months    (time) object ...\n",
      "    years     (time) int32 ...\n",
      "  * models    (models) object 'CCSM4_1' 'CCSM4_2' ... 'NorESM1-M_1'\n",
      "Dimensions without coordinates: time\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset('data/models_all_vars_vs_time.nc')\n",
    "X_ds = ds.to_array().transpose('models', 'time', 'variable')\n",
    "print(X_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_x = pdtw(X_ds, 'euclidean')\n",
    "print(D_x.shape)\n",
    "print(D_x)\n",
    "np.save(X_ds, '/data/dtw.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
